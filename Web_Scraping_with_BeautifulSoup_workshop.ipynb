{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/modouseck/first-repo/blob/main/Web_Scraping_with_BeautifulSoup_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GK0S-Eww-GNG"
      },
      "outputs": [],
      "source": [
        "#Requirements\n",
        "#pip3 install requests\n",
        "#pip3 install bs4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvY2OXgj-GNN"
      },
      "source": [
        "## Basic fundamentals of web scraping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_JVLUSu-GNP",
        "outputId": "466aa584-d46d-47f1-876a-5f5033b067b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is with html tags : <title>Fun with python programming – A programming language for revolution</title>\n",
            "this is without html tags: Fun with python programming\n",
            "<a class=\"screen-reader-text skip-link\" href=\"#content\">Skip to content</a>\n"
          ]
        }
      ],
      "source": [
        "# import these two modules bs4 for selecting HTML tags easily\n",
        "from bs4 import BeautifulSoup\n",
        "# requests module is easy to operate some people use urllib but I prefer this one because it is easy to use.\n",
        "import requests\n",
        "\n",
        "# I put here my own blog url ,you can change it.\n",
        "url=\"https://getpython.wordpress.com/\"\n",
        "\n",
        "#Requests module use to data from given url\n",
        "source=requests.get(url)\n",
        "\n",
        "# BeautifulSoup is used for getting HTML structure from requests response.(craete your soup)\n",
        "soup=BeautifulSoup(source.text,'html')\n",
        "\n",
        "# Find function is used to find a single element if there are more than once it always returns the first element.\n",
        "title=soup.find('title') # place your html tagg in parentheses that you want to find from html.\n",
        "print(\"this is with html tags :\",title)\n",
        "\n",
        "qwery=soup.find('h1') # here i find first h1 tagg in my website using find operation.\n",
        "\n",
        "#use .text for extract only text without any html tags\n",
        "print(\"this is without html tags:\",qwery.text)\n",
        "\n",
        "\n",
        "links=soup.find('a') #i extarcted link using \"a\" tag\n",
        "print(links)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PmNfxD4-GNS"
      },
      "source": [
        "## extarct data from innerhtml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QK95zHI-GNT",
        "outputId": "23d8588b-d5e7-40c6-db5e-20bb40c0a87d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#content\n"
          ]
        }
      ],
      "source": [
        "# here i extarcted href data from anchor tag.\n",
        "print(links['href'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xboUxCIH-GNT",
        "outputId": "118c5517-3906-4fe0-c3c5-afcb720a4f81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['screen-reader-text', 'skip-link']\n"
          ]
        }
      ],
      "source": [
        "# similarly i got class details from a anchor tag\n",
        "print(links['class'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiOXBzHu-GNU"
      },
      "source": [
        "## findall operation in Bs4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqsdZF07-GNV",
        "outputId": "8b88fbab-7daf-4edc-fb7a-9aee8ab8a541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total links in my website : 100\n",
            "\n",
            "<a class=\"screen-reader-text skip-link\" href=\"#content\">Skip to content</a>\n",
            "<a href=\"https://getpython.wordpress.com/\" rel=\"home\">\n",
            "<div class=\"cover\"></div>\n",
            "</a>\n",
            "<a class=\"screen-reader-text search-toggle\" href=\"#search-container\">Search</a>\n",
            "<a href=\"https://getpython.wordpress.com/\" rel=\"home\">Fun with python programming</a>\n",
            "<a aria-current=\"page\" href=\"/\">Home</a>\n",
            "<a href=\"https://getpython.wordpress.com/contact/\">Contact</a>\n"
          ]
        }
      ],
      "source": [
        "# findall function is used to fetch all tags at a single time.\n",
        "many_link=soup.find_all('a') # here i extracted all the anchor tags of my website\n",
        "total_links=len(many_link) # len function is use to calculate length of your array\n",
        "print(\"total links in my website :\",total_links)\n",
        "print()\n",
        "for i in many_link[:6]: # here i use slicing to fetch only first 6 links from rest of them.\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guqiX9BS-GNV",
        "outputId": "25ef0324-8bfa-4a88-955d-aa9bfcbd784b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<a href=\"https://getpython.wordpress.com/\" rel=\"home\">\n",
            "<div class=\"cover\"></div>\n",
            "</a>\n",
            "\n",
            "href is : https://getpython.wordpress.com/\n"
          ]
        }
      ],
      "source": [
        "second_link=many_link[1] #here i fetch second link which place on 1 index number in many_links.\n",
        "print(second_link)\n",
        "print()\n",
        "print(\"href is :\",second_link['href']) #only href link is extracted from ancor tag\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql6xCbGZ-GNW",
        "outputId": "c3bfd50d-863d-4e2c-cb3f-3991bb5c8c05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<div class=\"cover\"></div>\n",
            "\n",
            "['cover']\n",
            "<class 'list'>\n",
            "\n",
            "class name of div is : cover\n"
          ]
        }
      ],
      "source": [
        "# select div tag from second link\n",
        "nested_div=second_link.find('div')\n",
        "# As you can see div element extarcted , it also have inner elements\n",
        "print(nested_div)\n",
        "print()\n",
        "#here i extracted class element from div but it give us in the form of list\n",
        "z=(nested_div['class'])\n",
        "print(z)\n",
        "print(type(z))\n",
        "print()\n",
        "#  \" \" .join () method use to convert list type  into string type\n",
        "print(\"class name of div is :\",\" \".join(nested_div['class']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imUX0TMo-GNW"
      },
      "source": [
        "## scrap data from wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrUwKab7-GNW",
        "outputId": "4b4efee9-a80e-4ac1-8f6c-41c271799523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<title>World War II - Wikipedia</title>\n"
          ]
        }
      ],
      "source": [
        "wiki=requests.get(\"https://en.wikipedia.org/wiki/World_War_II\")\n",
        "soup=BeautifulSoup(wiki.text,'html')\n",
        "print(soup.find('title'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htEd7fJ--GNX"
      },
      "source": [
        "### find html tags with classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6dm-CS_-GNX"
      },
      "outputs": [],
      "source": [
        "ww2_contents=soup.find_all(\"div\",class_='toc')\n",
        "for i in ww2_contents:\n",
        "    print(i.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEwdhdhd-GNY",
        "outputId": "b3039b1e-0b01-4880-c07a-93a4eca0e937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "World War IIFrom top to bottom, left to right: \n",
            "German Stuka dive bombers on the Eastern Front, 1943\n",
            "British Matilda II tanks during the North African campaign, 1941\n",
            "U.S. atomic bombing of Nagasaki in Japan, 1945\n",
            "Soviet troops at the Battle of Stalingrad, 1943\n",
            "Soviet soldier raising a flag over the Reichstag after the Battle of Berlin, 1945\n",
            "U.S. warships in Lingayen Gulf in the Philippines, 1945\n",
            "Date1 September 1939 – 2 September 1945[a]  (6 years, 1 day)LocationMajor theatres: \n",
            "Europe\n",
            "Pacific\n",
            "Atlantic\n",
            "Indian Ocean\n",
            "South-East Asia\n",
            "China\n",
            "Japan\n",
            "Middle East\n",
            "Mediterranean\n",
            "North Africa\n",
            "Horn of Africa\n",
            "Central Africa\n",
            "Australia\n",
            "Caribbean\n",
            "North and South America\n",
            "Result\n",
            "Allied victory (see also aftermath of World War II)Participants\n",
            "Allies\n",
            "AxisCommanders and leaders\n",
            "Main Allied leaders:\n",
            " Joseph Stalin\n",
            " Franklin D. Roosevelt\n",
            " Winston Churchill\n",
            " Chiang Kai-shek\n",
            "\n",
            "Main Axis leaders:\n",
            " Adolf Hitler\n",
            " Hirohito\n",
            " Benito Mussolini\n",
            "Casualties and losses\n",
            "\n",
            "Military dead:\n",
            "Over 16,000,000\n",
            "Civilian dead:\n",
            "Over 45,000,000\n",
            "Total dead:\n",
            "Over 61,000,000\n",
            "(1937–1945)\n",
            "...further details\n",
            "\n",
            "\n",
            "Military dead:\n",
            "Over 8,000,000\n",
            "Civilian dead:\n",
            "Over 4,000,000\n",
            "Total dead:\n",
            "Over 12,000,000\n",
            "(1937–1945)\n",
            "...further details\n",
            "\n"
          ]
        }
      ],
      "source": [
        "overview=soup.find_all('table',class_='infobox vevent')\n",
        "for z in overview:\n",
        "    print(z.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html = \"\"\"<html><body><p>Hello World</p><a href=\"https://example.com\">Example</a></body></html>\"\"\"\n",
        "soup = BeautifulSoup(html, \"html.parser\")\n",
        "print(soup)\n",
        "# Extract the paragraph text\n",
        "print(soup.p.text)  # Output: Hello World\n",
        "\n",
        "# Extract the link URL\n",
        "print(soup.a['href'])  # Output: https://example.com"
      ],
      "metadata": {
        "id": "iAeLVAXws8NB",
        "outputId": "5d6c43aa-7dd0-4bb7-b248-c525002cfc1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<html><body><p>Hello World</p><a href=\"https://example.com\">Example</a></body></html>\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}